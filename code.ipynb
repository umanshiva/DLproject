{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BBUj-d-9fNl5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.nn import CTCLoss\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyTR1z03sWhE",
        "outputId": "d63d98bb-ba0f-466b-d275-8de39c9efed9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchinfo in d:\\anaconda3\\lib\\site-packages (1.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GBZpICPqgU4c"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'\n",
        "import torchinfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHc2tQ4MCFtK"
      },
      "source": [
        "# Custom Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5qYcaOkjCCtc"
      },
      "outputs": [],
      "source": [
        "## Creating a Custom Dataset class of loading and processing the Dataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, image_dir, labels_file, char_set, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.labels_file = labels_file\n",
        "        self.char_set = char_set\n",
        "        self.transform = transform\n",
        "\n",
        "        self.image_paths, self.labels = self._load_labels(labels_file)\n",
        "\n",
        "        self.char_to_idx = {char: idx for idx, char in enumerate(self.char_set, 1)}\n",
        "        self.blank_token = 0\n",
        "\n",
        "    def _load_labels(self, labels_file):\n",
        "        image_paths = []\n",
        "        labels = []\n",
        "        with open(labels_file, 'r') as f:\n",
        "            for line in f:\n",
        "                _,path, label = line.strip().split(',')\n",
        "                image_paths.append(os.path.join(self.image_dir, path))\n",
        "                labels.append(label)\n",
        "        return image_paths, labels\n",
        "\n",
        "    def _encode_label(self, label):\n",
        "        return [self.char_to_idx[char] for char in label]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.labels[idx]\n",
        "        label_encoded = torch.tensor(self._encode_label(label), dtype=torch.long)\n",
        "\n",
        "        return image, label_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oA-09ke3692o"
      },
      "outputs": [],
      "source": [
        "## The Characters the labels can have\n",
        "## 26 small and 26 Capital Alphabets, 0-9 numeric charaters and a blank space ' ' for any non-match\n",
        "our_char_set = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 '\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZKWHzJgGCoM-"
      },
      "outputs": [],
      "source": [
        "# ourt custom transform for transforming/processing images while loading\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.Resize((32, 100)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0)),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "\n",
        "dataset = TextDataset(image_dir='k\\\\dataset\\\\images',\n",
        "                                 labels_file='k\\\\dataset\\\\labels.csv',\n",
        "                                 char_set=our_char_set,\n",
        "                                 transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kXkPIKkADDxZ"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    images, labels = zip(*batch)\n",
        "    images = torch.stack(images, 0)\n",
        "    label_lengths = torch.tensor([len(label) for label in labels], dtype=torch.long)\n",
        "\n",
        "    return images, labels, label_lengths\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# our training dataset loader\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GRNiDdWDdQM"
      },
      "source": [
        "# RCNN arhitecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "z9xJfVQLgrid"
      },
      "outputs": [],
      "source": [
        "class Myarchitecture(nn.Module):\n",
        "  def __init__(self,input_shape, num_classes):\n",
        "    super(Myarchitecture, self).__init__()\n",
        "\n",
        "    self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape,\n",
        "                      out_channels=64,  # first conv layer maps to 64 channels\n",
        "                      kernel_size=3,  # 3x3 kernel\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2), stride=2)  # MaxPooling with window (2x2), stride=2\n",
        "        )\n",
        "\n",
        "    self.block_2 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels=64,\n",
        "                    out_channels=128,  # next conv layer maps to 128 channels\n",
        "                    kernel_size=3,\n",
        "                    stride=1,\n",
        "                    padding=1),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2)  # MaxPooling with window (2x2), stride=2\n",
        "    )\n",
        "\n",
        "    self.block_3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128,\n",
        "                      out_channels=256,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.Conv2d(in_channels=256,\n",
        "                      out_channels=256,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.MaxPool2d(kernel_size=(1,2), stride=2)  # MaxPooling with window (2x2), stride=2\n",
        "        )\n",
        "\n",
        "    self.block_4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256,\n",
        "                      out_channels=512,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.Conv2d(in_channels=512,\n",
        "                      out_channels=512,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.MaxPool2d(kernel_size=(1, 2), stride=2)  # MaxPooling with window (1x2),\n",
        "      )\n",
        "\n",
        "    self.block_5  = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=512,\n",
        "                    out_channels=512,\n",
        "                    kernel_size=2,  # 2x2 kernel as per architecture\n",
        "                    stride=1,\n",
        "                    padding=0),\n",
        "\n",
        "    )\n",
        "\n",
        "    self.lstm = nn.LSTM(input_size = 512, hidden_size = 256, num_layers = 2, bidirectional = True, batch_first = True)\n",
        "\n",
        "    self.classifier = nn.Linear(256*2, num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.block_1(x)\n",
        "    x = self.block_2(x)\n",
        "    x = self.block_3(x)\n",
        "    x = self.block_4(x)\n",
        "    x = self.block_5(x)\n",
        "\n",
        "    x = x.squeeze(2).permute(0,2,1)\n",
        "\n",
        "    x,_= self.lstm(x)\n",
        "\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCLXrUPPweUs",
        "outputId": "27db9608-35aa-4647-96ac-b54e3428de1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary of the architecture(batch_size = 32): \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Myarchitecture                           [32, 5, 63]               --\n",
              "├─Sequential: 1-1                        [32, 64, 16, 50]          --\n",
              "│    └─Conv2d: 2-1                       [32, 64, 32, 100]         640\n",
              "│    └─MaxPool2d: 2-2                    [32, 64, 16, 50]          --\n",
              "├─Sequential: 1-2                        [32, 128, 8, 25]          --\n",
              "│    └─Conv2d: 2-3                       [32, 128, 16, 50]         73,856\n",
              "│    └─MaxPool2d: 2-4                    [32, 128, 8, 25]          --\n",
              "├─Sequential: 1-3                        [32, 256, 4, 12]          --\n",
              "│    └─Conv2d: 2-5                       [32, 256, 8, 25]          295,168\n",
              "│    └─Conv2d: 2-6                       [32, 256, 8, 25]          590,080\n",
              "│    └─MaxPool2d: 2-7                    [32, 256, 4, 12]          --\n",
              "├─Sequential: 1-4                        [32, 512, 2, 6]           --\n",
              "│    └─Conv2d: 2-8                       [32, 512, 4, 12]          1,180,160\n",
              "│    └─BatchNorm2d: 2-9                  [32, 512, 4, 12]          1,024\n",
              "│    └─Conv2d: 2-10                      [32, 512, 4, 12]          2,359,808\n",
              "│    └─BatchNorm2d: 2-11                 [32, 512, 4, 12]          1,024\n",
              "│    └─MaxPool2d: 2-12                   [32, 512, 2, 6]           --\n",
              "├─Sequential: 1-5                        [32, 512, 1, 5]           --\n",
              "│    └─Conv2d: 2-13                      [32, 512, 1, 5]           1,049,088\n",
              "├─LSTM: 1-6                              [32, 5, 512]              3,153,920\n",
              "├─Linear: 1-7                            [32, 5, 63]               32,319\n",
              "==========================================================================================\n",
              "Total params: 8,737,087\n",
              "Trainable params: 8,737,087\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 13.73\n",
              "==========================================================================================\n",
              "Input size (MB): 0.41\n",
              "Forward/backward pass size (MB): 131.41\n",
              "Params size (MB): 34.95\n",
              "Estimated Total Size (MB): 166.77\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Creationng the instance of the class\n",
        "mymodel = Myarchitecture(input_shape=1, num_classes=63)\n",
        "mymodel.to(device)\n",
        "print(\"Summary of the architecture(batch_size = 32): \")\n",
        "torchinfo.summary(mymodel, input_size=(32,1,32,100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "j9gnWsBb4ZTZ"
      },
      "outputs": [],
      "source": [
        "def lexicon_free_transcription(y_pred, blank=62):  # index 62 is for the space in our character set\n",
        "\n",
        "    pred = torch.argmax(y, dim=2)\n",
        "    pred = pred.transpose(0, 1)  # (batch_size, seq_len) -> (seq_len, batch_size)\n",
        "\n",
        "    decoded_labels = []\n",
        "    for sequence in pred:\n",
        "        prev_char = blank\n",
        "        decoded_seq = []\n",
        "        for char_idx in sequence:\n",
        "            if char_idx != prev_char and char_idx != blank:\n",
        "                decoded_seq.append(char_idx.item())  # Append non-blank, non-repeating character\n",
        "            prev_char = char_idx\n",
        "        decoded_labels.append(decoded_seq)\n",
        "\n",
        "    return decoded_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_6WBxBRaBHXC"
      },
      "outputs": [],
      "source": [
        "## loss function definition\n",
        "loss_fun = CTCLoss(blank=62)\n",
        "\n",
        "## optimizer\n",
        "optimizer = optim.Adadelta(mymodel.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## yet to train.."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
